Starting Fixed Adversarial Watermarking Training...
Loading models...
Loading C1 model...
/teamspace/studios/this_studio/unetMRI/src/watermarking/MRI_Watermark_Embedding_CYCLES_FIXED_ADVERSARIAL.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(C1_PATH, map_location=DEVICE)
/teamspace/studios/this_studio/unetMRI/src/watermarking/MRI_Watermark_Embedding_CYCLES_FIXED_ADVERSARIAL.py:273: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(AE_PATH, map_location=DEVICE)
Starting training...
\n=== EPOCH 1/5 ===
WARMUP STAGE - Training C2 normally
ğŸ”„ Creating dataloader for warmup stage...
ğŸ“¦ Creating dataloader: warmup stage, batch_size=64
Batch 0: C2_loss=4.949, C1_acc=0.984, C2_acc=0.250
Batch 10: C2_loss=2.620, C1_acc=1.000, C2_acc=0.344
Batch 20: C2_loss=1.257, C1_acc=1.000, C2_acc=0.531
Batch 30: C2_loss=1.198, C1_acc=1.000, C2_acc=0.562
Batch 40: C2_loss=1.263, C1_acc=1.000, C2_acc=0.672
Batch 50: C2_loss=1.213, C1_acc=1.000, C2_acc=0.641
Batch 60: C2_loss=0.810, C1_acc=1.000, C2_acc=0.672
Batch 70: C2_loss=0.913, C1_acc=1.000, C2_acc=0.609
Batch 80: C2_loss=0.780, C1_acc=1.000, C2_acc=0.766
Epoch 1 Summary:
  Stage: warmup
  C1 Performance: clean=0.998
  C2 Performance: clean=0.545
\n=== EPOCH 2/5 ===
ADVERSARIAL STAGE - C2 vs Generator
ğŸ”„ Creating dataloader for adversarial stage...
ğŸ“¦ Creating dataloader: adversarial stage, batch_size=16
Batch 0: C2_loss=31.911, Gen_loss=9.057
  C1: clean=1.000, wm=1.000
  C2: clean=0.625, wm=0.500
  Quality: L1=0.0003
  Losses: Misclassify=5.869, Fooling=4.528
Batch 10: C2_loss=11.676, Gen_loss=5.927
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.188
  Quality: L1=0.0005
  Losses: Misclassify=1.457, Fooling=2.964
Batch 20: C2_loss=17.155, Gen_loss=2.757
  C1: clean=1.000, wm=1.000
  C2: clean=0.062, wm=0.438
  Quality: L1=0.0003
  Losses: Misclassify=2.395, Fooling=1.379
Batch 30: C2_loss=11.632, Gen_loss=2.965
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.438
  Quality: L1=0.0003
  Losses: Misclassify=1.325, Fooling=1.483
Batch 40: C2_loss=12.293, Gen_loss=2.980
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.312
  Quality: L1=0.0003
  Losses: Misclassify=1.424, Fooling=1.490
Batch 50: C2_loss=16.655, Gen_loss=2.908
  C1: clean=1.000, wm=1.000
  C2: clean=0.125, wm=0.312
  Quality: L1=0.0004
  Losses: Misclassify=2.509, Fooling=1.454
Batch 60: C2_loss=11.094, Gen_loss=3.190
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.188
  Quality: L1=0.0003
  Losses: Misclassify=1.299, Fooling=1.595
Batch 70: C2_loss=12.753, Gen_loss=4.089
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.312
  Quality: L1=0.0004
  Losses: Misclassify=1.738, Fooling=2.044
Batch 80: C2_loss=12.440, Gen_loss=2.638
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.062
  Quality: L1=0.0005
  Losses: Misclassify=1.604, Fooling=1.319
Batch 90: C2_loss=12.992, Gen_loss=3.055
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.125
  Quality: L1=0.0006
  Losses: Misclassify=1.753, Fooling=1.527
Batch 100: C2_loss=10.665, Gen_loss=3.001
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.438
  Quality: L1=0.0006
  Losses: Misclassify=1.334, Fooling=1.500
Batch 110: C2_loss=11.767, Gen_loss=2.799
  C1: clean=1.000, wm=1.000
  C2: clean=0.125, wm=0.312
  Quality: L1=0.0005
  Losses: Misclassify=1.538, Fooling=1.400
Batch 120: C2_loss=10.912, Gen_loss=3.247
  C1: clean=0.938, wm=0.938
  C2: clean=0.062, wm=0.188
  Quality: L1=0.0005
  Losses: Misclassify=1.286, Fooling=1.624
Batch 130: C2_loss=11.734, Gen_loss=3.015
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.438
  Quality: L1=0.0006
  Losses: Misclassify=1.603, Fooling=1.508
Batch 140: C2_loss=12.014, Gen_loss=3.098
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.188
  Quality: L1=0.0007
  Losses: Misclassify=1.623, Fooling=1.549
Batch 150: C2_loss=10.790, Gen_loss=3.612
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.312
  Quality: L1=0.0007
  Losses: Misclassify=1.377, Fooling=1.806
Batch 160: C2_loss=12.172, Gen_loss=2.938
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.375
  Quality: L1=0.0006
  Losses: Misclassify=1.663, Fooling=1.469
Batch 170: C2_loss=13.630, Gen_loss=3.131
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.188
  Quality: L1=0.0006
  Losses: Misclassify=1.764, Fooling=1.565
Batch 180: C2_loss=13.101, Gen_loss=2.880
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.250
  Quality: L1=0.0006
  Losses: Misclassify=1.801, Fooling=1.440
Batch 190: C2_loss=11.561, Gen_loss=2.776
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.250
  Quality: L1=0.0006
  Losses: Misclassify=1.433, Fooling=1.388
Batch 200: C2_loss=11.496, Gen_loss=233676.203
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.250
  Quality: L1=0.0006
  Losses: Misclassify=1.461, Fooling=1.532
Batch 210: C2_loss=11.327, Gen_loss=3.231
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.312
  Quality: L1=0.0007
  Losses: Misclassify=1.317, Fooling=1.615
Batch 220: C2_loss=11.479, Gen_loss=2.685
  C1: clean=1.000, wm=1.000
  C2: clean=0.500, wm=0.438
  Quality: L1=0.0007
  Losses: Misclassify=1.520, Fooling=1.343
Batch 230: C2_loss=10.611, Gen_loss=3.661
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.500
  Quality: L1=0.0007
  Losses: Misclassify=1.345, Fooling=1.831
Batch 240: C2_loss=11.185, Gen_loss=2.785
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.500
  Quality: L1=0.0008
  Losses: Misclassify=1.491, Fooling=1.392
Batch 250: C2_loss=11.259, Gen_loss=2.933
  C1: clean=1.000, wm=1.000
  C2: clean=0.750, wm=0.500
  Quality: L1=0.0008
  Losses: Misclassify=1.495, Fooling=1.466
Batch 260: C2_loss=11.123, Gen_loss=3.095
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.438
  Quality: L1=0.0008
  Losses: Misclassify=1.383, Fooling=1.547
Batch 270: C2_loss=11.406, Gen_loss=2.740
  C1: clean=1.000, wm=1.000
  C2: clean=0.625, wm=0.562
  Quality: L1=0.0008
  Losses: Misclassify=1.452, Fooling=1.370
Batch 280: C2_loss=10.675, Gen_loss=3.199
  C1: clean=1.000, wm=1.000
  C2: clean=0.500, wm=0.500
  Quality: L1=0.0008
  Losses: Misclassify=1.357, Fooling=1.600
Batch 290: C2_loss=11.170, Gen_loss=3.083
  C1: clean=1.000, wm=1.000
  C2: clean=0.500, wm=0.562
  Quality: L1=0.0008
  Losses: Misclassify=1.490, Fooling=1.542
Batch 300: C2_loss=11.923, Gen_loss=211303.906
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.438
  Quality: L1=0.0008
  Losses: Misclassify=1.419, Fooling=1.595
Batch 310: C2_loss=11.889, Gen_loss=2.927
  C1: clean=1.000, wm=1.000
  C2: clean=0.125, wm=0.312
  Quality: L1=0.0008
  Losses: Misclassify=1.560, Fooling=1.464
Batch 320: C2_loss=11.791, Gen_loss=2.786
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.375
  Quality: L1=0.0008
  Losses: Misclassify=1.539, Fooling=1.393
Batch 330: C2_loss=11.362, Gen_loss=3.094
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.312
  Quality: L1=0.0009
  Losses: Misclassify=1.486, Fooling=1.547
Batch 340: C2_loss=10.890, Gen_loss=2.530
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.500
  Quality: L1=0.0010
  Losses: Misclassify=1.393, Fooling=1.265
Batch 350: C2_loss=11.270, Gen_loss=2.749
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.312
  Quality: L1=0.0011
  Losses: Misclassify=1.459, Fooling=1.375
Epoch 2 Summary:
  Stage: adversarial
  C1 Performance: clean=0.998, wm=0.998
  C2 Performance: clean=0.335, wm=0.335
  Quality: L1=0.0006
  Watermark Signal: intensity=0.300, entropy_clean=0.000
  âš ï¸  C2 is not detecting watermarks well enough
\n=== EPOCH 3/5 ===
ADVERSARIAL STAGE - C2 vs Generator
Batch 0: C2_loss=11.558, Gen_loss=3.162
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.312
  Quality: L1=0.0009
  Losses: Misclassify=1.512, Fooling=1.581
Batch 10: C2_loss=11.280, Gen_loss=3.017
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.250
  Quality: L1=0.0005
  Losses: Misclassify=1.448, Fooling=1.508
Batch 20: C2_loss=11.849, Gen_loss=3.107
  C1: clean=0.938, wm=0.938
  C2: clean=0.312, wm=0.312
  Quality: L1=0.0006
  Losses: Misclassify=1.527, Fooling=1.554
Batch 30: C2_loss=11.399, Gen_loss=3.323
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.250
  Quality: L1=0.0011
  Losses: Misclassify=1.500, Fooling=1.662
Batch 40: C2_loss=11.470, Gen_loss=3.192
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.250
  Quality: L1=0.0013
  Losses: Misclassify=1.367, Fooling=1.596
Batch 50: C2_loss=11.104, Gen_loss=2.988
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.438
  Quality: L1=0.0015
  Losses: Misclassify=1.481, Fooling=1.494
Batch 60: C2_loss=13.379, Gen_loss=3.071
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.438
  Quality: L1=0.0013
  Losses: Misclassify=1.858, Fooling=1.535
Batch 70: C2_loss=10.664, Gen_loss=2.762
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.312
  Quality: L1=0.0010
  Losses: Misclassify=1.311, Fooling=1.381
Batch 80: C2_loss=12.178, Gen_loss=2.724
  C1: clean=1.000, wm=1.000
  C2: clean=0.000, wm=0.250
  Quality: L1=0.0007
  Losses: Misclassify=1.642, Fooling=1.362
Batch 90: C2_loss=12.064, Gen_loss=3.151
  C1: clean=1.000, wm=1.000
  C2: clean=0.125, wm=0.312
  Quality: L1=0.0006
  Losses: Misclassify=1.492, Fooling=1.576
Batch 100: C2_loss=10.488, Gen_loss=3.176
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.688
  Quality: L1=0.0005
  Losses: Misclassify=1.334, Fooling=1.588
Batch 110: C2_loss=10.772, Gen_loss=2.778
  C1: clean=1.000, wm=1.000
  C2: clean=0.125, wm=0.188
  Quality: L1=0.0006
  Losses: Misclassify=1.343, Fooling=1.389
Batch 120: C2_loss=11.501, Gen_loss=2.954
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.375
  Quality: L1=0.0007
  Losses: Misclassify=1.421, Fooling=1.477
Batch 130: C2_loss=11.863, Gen_loss=2.735
  C1: clean=1.000, wm=1.000
  C2: clean=0.500, wm=0.312
  Quality: L1=0.0009
  Losses: Misclassify=1.540, Fooling=1.368
Batch 140: C2_loss=11.924, Gen_loss=2.975
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.312
  Quality: L1=0.0009
  Losses: Misclassify=1.514, Fooling=1.487
Batch 150: C2_loss=11.297, Gen_loss=3.104
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.250
  Quality: L1=0.0008
  Losses: Misclassify=1.412, Fooling=1.552
Batch 160: C2_loss=11.179, Gen_loss=2.712
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.438
  Quality: L1=0.0010
  Losses: Misclassify=1.358, Fooling=1.356
Batch 170: C2_loss=11.817, Gen_loss=2.848
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.500
  Quality: L1=0.0011
  Losses: Misclassify=1.555, Fooling=1.424
Batch 180: C2_loss=10.548, Gen_loss=2.817
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.375
  Quality: L1=0.0011
  Losses: Misclassify=1.332, Fooling=1.409
Batch 190: C2_loss=12.022, Gen_loss=2.974
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.125
  Quality: L1=0.0010
  Losses: Misclassify=1.579, Fooling=1.487
Batch 200: C2_loss=11.367, Gen_loss=2.877
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.312
  Quality: L1=0.0009
  Losses: Misclassify=1.385, Fooling=1.439
Batch 210: C2_loss=11.385, Gen_loss=2.794
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.375
  Quality: L1=0.0009
  Losses: Misclassify=1.465, Fooling=1.397
Batch 220: C2_loss=10.983, Gen_loss=2.860
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.125
  Quality: L1=0.0008
  Losses: Misclassify=1.342, Fooling=1.430
Batch 230: C2_loss=11.689, Gen_loss=3.023
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.250
  Quality: L1=0.0007
  Losses: Misclassify=1.550, Fooling=1.512
Batch 240: C2_loss=11.089, Gen_loss=3.203
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.250
  Quality: L1=0.0006
  Losses: Misclassify=1.430, Fooling=1.602
Batch 250: C2_loss=11.238, Gen_loss=215397.797
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.312
  Quality: L1=0.0006
  Losses: Misclassify=1.475, Fooling=1.476
Batch 260: C2_loss=11.231, Gen_loss=202702.953
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.438
  Quality: L1=0.0008
  Losses: Misclassify=1.413, Fooling=1.396
Batch 270: C2_loss=11.374, Gen_loss=2.595
  C1: clean=1.000, wm=1.000
  C2: clean=0.500, wm=0.312
  Quality: L1=0.0009
  Losses: Misclassify=1.482, Fooling=1.297
Batch 280: C2_loss=11.581, Gen_loss=191091.875
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.250
  Quality: L1=0.0010
  Losses: Misclassify=1.504, Fooling=1.336
Batch 290: C2_loss=11.176, Gen_loss=2.782
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.375
  Quality: L1=0.0010
  Losses: Misclassify=1.408, Fooling=1.391
Batch 300: C2_loss=11.251, Gen_loss=2.808
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.438
  Quality: L1=0.0010
  Losses: Misclassify=1.404, Fooling=1.404
Batch 310: C2_loss=12.018, Gen_loss=2.759
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.062
  Quality: L1=0.0010
  Losses: Misclassify=1.559, Fooling=1.380
Batch 320: C2_loss=11.331, Gen_loss=2.649
  C1: clean=1.000, wm=1.000
  C2: clean=0.125, wm=0.250
  Quality: L1=0.0008
  Losses: Misclassify=1.453, Fooling=1.324
Batch 330: C2_loss=10.773, Gen_loss=2.998
  C1: clean=1.000, wm=1.000
  C2: clean=0.500, wm=0.500
  Quality: L1=0.0009
  Losses: Misclassify=1.368, Fooling=1.499
Batch 340: C2_loss=10.720, Gen_loss=2.712
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.375
  Quality: L1=0.0009
  Losses: Misclassify=1.284, Fooling=1.356
Batch 350: C2_loss=10.834, Gen_loss=2.797
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.375
  Quality: L1=0.0009
  Losses: Misclassify=1.372, Fooling=1.399
Epoch 3 Summary:
  Stage: adversarial
  C1 Performance: clean=0.998, wm=0.998
  C2 Performance: clean=0.331, wm=0.328
  Quality: L1=0.0009
  Watermark Signal: intensity=0.300, entropy_clean=0.000
  âš ï¸  C2 is not detecting watermarks well enough
  ğŸ“ˆ C2 watermark detection too low (0.328), increased intensity to 0.330
  ğŸ“Š C2 Distinction Score: -0.004 (target: >0.5)
  ğŸš¨ C2 cannot distinguish watermarked from clean! Increasing watermark strength...
\n=== EPOCH 4/5 ===
ADVERSARIAL STAGE - C2 vs Generator
Batch 0: C2_loss=10.867, Gen_loss=3.285
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.500
  Quality: L1=0.0014
  Losses: Misclassify=1.416, Fooling=1.643
Batch 10: C2_loss=11.619, Gen_loss=2.952
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.312
  Quality: L1=0.0007
  Losses: Misclassify=1.523, Fooling=1.476
Batch 20: C2_loss=10.798, Gen_loss=2.765
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.250
  Quality: L1=0.0009
  Losses: Misclassify=1.337, Fooling=1.382
Batch 30: C2_loss=11.405, Gen_loss=2.840
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.250
  Quality: L1=0.0011
  Losses: Misclassify=1.453, Fooling=1.420
Batch 40: C2_loss=10.805, Gen_loss=2.736
  C1: clean=1.000, wm=1.000
  C2: clean=0.125, wm=0.188
  Quality: L1=0.0010
  Losses: Misclassify=1.347, Fooling=1.368
Batch 50: C2_loss=11.201, Gen_loss=3.244
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.312
  Quality: L1=0.0007
  Losses: Misclassify=1.408, Fooling=1.622
Batch 60: C2_loss=11.860, Gen_loss=2.700
  C1: clean=1.000, wm=1.000
  C2: clean=0.625, wm=0.562
  Quality: L1=0.0006
  Losses: Misclassify=1.588, Fooling=1.350
Batch 70: C2_loss=11.206, Gen_loss=2.785
  C1: clean=0.938, wm=0.938
  C2: clean=0.188, wm=0.188
  Quality: L1=0.0007
  Losses: Misclassify=1.408, Fooling=1.393
Batch 80: C2_loss=11.525, Gen_loss=2.814
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.312
  Quality: L1=0.0006
  Losses: Misclassify=1.469, Fooling=1.407
Batch 90: C2_loss=11.426, Gen_loss=3.012
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.375
  Quality: L1=0.0008
  Losses: Misclassify=1.500, Fooling=1.506
Batch 100: C2_loss=11.160, Gen_loss=549295.938
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.438
  Quality: L1=0.0008
  Losses: Misclassify=1.471, Fooling=1.393
Batch 110: C2_loss=12.223, Gen_loss=2.771
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.500
  Quality: L1=0.0008
  Losses: Misclassify=1.552, Fooling=1.385
Batch 120: C2_loss=11.278, Gen_loss=2.795
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.312
  Quality: L1=0.0007
  Losses: Misclassify=1.418, Fooling=1.397
Batch 130: C2_loss=12.326, Gen_loss=2.694
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.188
  Quality: L1=0.0007
  Losses: Misclassify=1.433, Fooling=1.347
Batch 140: C2_loss=12.211, Gen_loss=2.833
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.062
  Quality: L1=0.0008
  Losses: Misclassify=1.612, Fooling=1.416
Batch 150: C2_loss=11.871, Gen_loss=2.729
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.188
  Quality: L1=0.0007
  Losses: Misclassify=1.475, Fooling=1.365
Batch 160: C2_loss=11.291, Gen_loss=3.015
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.188
  Quality: L1=0.0011
  Losses: Misclassify=1.303, Fooling=1.507
Batch 170: C2_loss=11.612, Gen_loss=3.097
  C1: clean=0.938, wm=0.938
  C2: clean=0.375, wm=0.125
  Quality: L1=0.0013
  Losses: Misclassify=1.371, Fooling=1.549
Batch 180: C2_loss=10.941, Gen_loss=2.950
  C1: clean=1.000, wm=1.000
  C2: clean=0.125, wm=0.312
  Quality: L1=0.0014
  Losses: Misclassify=1.377, Fooling=1.475
Batch 190: C2_loss=12.349, Gen_loss=2.892
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.188
  Quality: L1=0.0013
  Losses: Misclassify=1.622, Fooling=1.446
Batch 200: C2_loss=11.116, Gen_loss=255021.078
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.438
  Quality: L1=0.0010
  Losses: Misclassify=1.425, Fooling=1.432
Batch 210: C2_loss=11.230, Gen_loss=2.745
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.312
  Quality: L1=0.0010
  Losses: Misclassify=1.403, Fooling=1.373
Batch 220: C2_loss=11.697, Gen_loss=2.819
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.312
  Quality: L1=0.0011
  Losses: Misclassify=1.524, Fooling=1.409
Batch 230: C2_loss=11.075, Gen_loss=2.873
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.375
  Quality: L1=0.0012
  Losses: Misclassify=1.403, Fooling=1.437
Batch 240: C2_loss=10.915, Gen_loss=2.876
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.312
  Quality: L1=0.0012
  Losses: Misclassify=1.345, Fooling=1.438
Batch 250: C2_loss=11.103, Gen_loss=3.014
  C1: clean=1.000, wm=1.000
  C2: clean=0.500, wm=0.438
  Quality: L1=0.0017
  Losses: Misclassify=1.433, Fooling=1.507
Batch 260: C2_loss=11.896, Gen_loss=3.033
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.250
  Quality: L1=0.0019
  Losses: Misclassify=1.538, Fooling=1.517
Batch 270: C2_loss=10.730, Gen_loss=2.841
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.250
  Quality: L1=0.0021
  Losses: Misclassify=1.358, Fooling=1.420
Batch 280: C2_loss=11.186, Gen_loss=2.898
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.500
  Quality: L1=0.0024
  Losses: Misclassify=1.455, Fooling=1.449
Batch 290: C2_loss=11.478, Gen_loss=2.932
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.312
  Quality: L1=0.0024
  Losses: Misclassify=1.479, Fooling=1.466
Batch 300: C2_loss=10.886, Gen_loss=2.768
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.125
  Quality: L1=0.0024
  Losses: Misclassify=1.359, Fooling=1.384
Batch 310: C2_loss=11.317, Gen_loss=2.917
  C1: clean=0.938, wm=0.938
  C2: clean=0.375, wm=0.438
  Quality: L1=0.0028
  Losses: Misclassify=1.424, Fooling=1.458
Batch 320: C2_loss=11.379, Gen_loss=260589.734
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.250
  Quality: L1=0.0026
  Losses: Misclassify=1.480, Fooling=1.425
Batch 330: C2_loss=11.690, Gen_loss=2.748
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.312
  Quality: L1=0.0028
  Losses: Misclassify=1.470, Fooling=1.374
Batch 340: C2_loss=10.951, Gen_loss=2.918
  C1: clean=1.000, wm=1.000
  C2: clean=0.562, wm=0.500
  Quality: L1=0.0024
  Losses: Misclassify=1.408, Fooling=1.459
Batch 350: C2_loss=10.727, Gen_loss=3.064
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.312
  Quality: L1=0.0026
  Losses: Misclassify=1.326, Fooling=1.532
Epoch 4 Summary:
  Stage: adversarial
  C1 Performance: clean=0.998, wm=0.998
  C2 Performance: clean=0.317, wm=0.315
  Quality: L1=0.0014
  Watermark Signal: intensity=0.396, entropy_clean=0.000
  âš ï¸  C2 is not detecting watermarks well enough
  ğŸ“ˆ C2 watermark detection too low (0.315), increased intensity to 0.436
  ğŸ“Š C2 Distinction Score: -0.002 (target: >0.5)
  ğŸš¨ C2 cannot distinguish watermarked from clean! Increasing watermark strength...
\n=== EPOCH 5/5 ===
ADVERSARIAL STAGE - C2 vs Generator
Batch 0: C2_loss=10.896, Gen_loss=2.622
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.250
  Quality: L1=0.0034
  Losses: Misclassify=1.383, Fooling=1.311
Batch 10: C2_loss=11.448, Gen_loss=2.756
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.250
  Quality: L1=0.0031
  Losses: Misclassify=1.418, Fooling=1.378
Batch 20: C2_loss=11.232, Gen_loss=2.826
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.375
  Quality: L1=0.0025
  Losses: Misclassify=1.388, Fooling=1.413
Batch 30: C2_loss=11.820, Gen_loss=2.893
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.375
  Quality: L1=0.0021
  Losses: Misclassify=1.478, Fooling=1.446
Batch 40: C2_loss=10.767, Gen_loss=2.763
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.375
  Quality: L1=0.0019
  Losses: Misclassify=1.410, Fooling=1.382
Batch 50: C2_loss=11.408, Gen_loss=2.851
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.250
  Quality: L1=0.0014
  Losses: Misclassify=1.509, Fooling=1.426
Batch 60: C2_loss=11.188, Gen_loss=2.711
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.375
  Quality: L1=0.0012
  Losses: Misclassify=1.415, Fooling=1.356
Batch 70: C2_loss=11.513, Gen_loss=3.115
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.312
  Quality: L1=0.0009
  Losses: Misclassify=1.475, Fooling=1.557
Batch 80: C2_loss=11.592, Gen_loss=2.799
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.375
  Quality: L1=0.0012
  Losses: Misclassify=1.525, Fooling=1.400
Batch 90: C2_loss=11.321, Gen_loss=2.876
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.312
  Quality: L1=0.0012
  Losses: Misclassify=1.451, Fooling=1.438
Batch 100: C2_loss=11.334, Gen_loss=2.858
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.438
  Quality: L1=0.0019
  Losses: Misclassify=1.472, Fooling=1.429
Batch 110: C2_loss=11.545, Gen_loss=2.758
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.375
  Quality: L1=0.0020
  Losses: Misclassify=1.440, Fooling=1.379
Batch 120: C2_loss=11.162, Gen_loss=3.057
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.188
  Quality: L1=0.0016
  Losses: Misclassify=1.447, Fooling=1.529
Batch 130: C2_loss=12.085, Gen_loss=2.997
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.312
  Quality: L1=0.0025
  Losses: Misclassify=1.519, Fooling=1.498
Batch 140: C2_loss=11.440, Gen_loss=2.792
  C1: clean=0.938, wm=0.938
  C2: clean=0.250, wm=0.188
  Quality: L1=0.0026
  Losses: Misclassify=1.438, Fooling=1.396
Batch 150: C2_loss=10.547, Gen_loss=2.735
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.500
  Quality: L1=0.0025
  Losses: Misclassify=1.351, Fooling=1.367
Batch 160: C2_loss=11.429, Gen_loss=3.105
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.500
  Quality: L1=0.0028
  Losses: Misclassify=1.577, Fooling=1.553
Batch 170: C2_loss=10.772, Gen_loss=3.030
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.375
  Quality: L1=0.0034
  Losses: Misclassify=1.373, Fooling=1.515
Batch 180: C2_loss=10.961, Gen_loss=2.734
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.188
  Quality: L1=0.0024
  Losses: Misclassify=1.316, Fooling=1.367
Batch 190: C2_loss=11.245, Gen_loss=2.868
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.375
  Quality: L1=0.0032
  Losses: Misclassify=1.474, Fooling=1.434
Batch 200: C2_loss=11.379, Gen_loss=2.928
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.375
  Quality: L1=0.0027
  Losses: Misclassify=1.513, Fooling=1.464
Batch 210: C2_loss=10.833, Gen_loss=2.707
  C1: clean=1.000, wm=1.000
  C2: clean=0.562, wm=0.500
  Quality: L1=0.0044
  Losses: Misclassify=1.361, Fooling=1.354
Batch 220: C2_loss=11.581, Gen_loss=2.887
  C1: clean=1.000, wm=1.000
  C2: clean=0.125, wm=0.188
  Quality: L1=0.0046
  Losses: Misclassify=1.398, Fooling=1.444
Batch 230: C2_loss=11.527, Gen_loss=2.748
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.312
  Quality: L1=0.0029
  Losses: Misclassify=1.464, Fooling=1.374
Batch 240: C2_loss=11.512, Gen_loss=2.811
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.312
  Quality: L1=0.0021
  Losses: Misclassify=1.455, Fooling=1.405
Batch 250: C2_loss=10.835, Gen_loss=2.773
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.188
  Quality: L1=0.0028
  Losses: Misclassify=1.363, Fooling=1.387
Batch 260: C2_loss=11.704, Gen_loss=2.805
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.312
  Quality: L1=0.0023
  Losses: Misclassify=1.546, Fooling=1.402
Batch 270: C2_loss=11.719, Gen_loss=2.849
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.188
  Quality: L1=0.0030
  Losses: Misclassify=1.447, Fooling=1.425
Batch 280: C2_loss=11.130, Gen_loss=2.894
  C1: clean=1.000, wm=1.000
  C2: clean=0.250, wm=0.312
  Quality: L1=0.0036
  Losses: Misclassify=1.402, Fooling=1.447
Batch 290: C2_loss=11.207, Gen_loss=2.876
  C1: clean=1.000, wm=1.000
  C2: clean=0.312, wm=0.438
  Quality: L1=0.0027
  Losses: Misclassify=1.421, Fooling=1.438
Batch 300: C2_loss=11.276, Gen_loss=2.796
  C1: clean=1.000, wm=1.000
  C2: clean=0.188, wm=0.125
  Quality: L1=0.0025
  Losses: Misclassify=1.371, Fooling=1.398
Batch 310: C2_loss=11.479, Gen_loss=3.005
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.312
  Quality: L1=0.0032
  Losses: Misclassify=1.488, Fooling=1.503
Batch 320: C2_loss=11.713, Gen_loss=2.726
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.312
  Quality: L1=0.0027
  Losses: Misclassify=1.502, Fooling=1.363
Batch 330: C2_loss=11.875, Gen_loss=2.977
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.250
  Quality: L1=0.0021
  Losses: Misclassify=1.515, Fooling=1.488
Batch 340: C2_loss=10.981, Gen_loss=3.096
  C1: clean=1.000, wm=1.000
  C2: clean=0.375, wm=0.375
  Quality: L1=0.0023
  Losses: Misclassify=1.374, Fooling=1.548
Batch 350: C2_loss=11.486, Gen_loss=2.811
  C1: clean=1.000, wm=1.000
  C2: clean=0.438, wm=0.375
  Quality: L1=0.0021
  Losses: Misclassify=1.493, Fooling=1.406
Epoch 5 Summary:
  Stage: adversarial
  C1 Performance: clean=0.998, wm=0.999
  C2 Performance: clean=0.321, wm=0.319
  Quality: L1=0.0025
  Watermark Signal: intensity=0.523, entropy_clean=0.000
  âš ï¸  C2 is not detecting watermarks well enough
  ğŸ’¾ Checkpoint saved
  ğŸ“ˆ C2 watermark detection too low (0.319), increased intensity to 0.575
  ğŸ“Š C2 Distinction Score: -0.002 (target: >0.5)
  ğŸš¨ C2 cannot distinguish watermarked from clean! Increasing watermark strength...
\nğŸ‰ Training completed! Results saved to /teamspace/studios/this_studio/unetMRI/output/csv_logs_FIXED/final_training_results.csv
\nFinal Performance:
  C1: clean=0.998, wm=0.999
  C2: clean=0.321, wm=0.319
\nâŒ Goals not fully achieved - check parameters and continue training
